{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Business Understanding\nThe Seattle government is going to prevent avoidable car accidents by employing methods that alert drivers, health system, and police to remind them to be more careful in critical situations.\nIn most cases, not paying enough attention during driving, abusing drugs and alcohol or driving at very high speed are the main causes of occurring accidents that can be prevented by enacting harsher regulations. Besides the aforementioned reasons, weather, visibility, or road conditions are the major uncontrollable factors that can be prevented by revealing hidden patterns in the data and announcing warning to the local government, police and drivers on the targeted roads.\nThe target audience of the project is local Seattle government, police, rescue groups, and last but not least, car insurance institutes. The model and its results are going to provide some advice for the target audience to make insightful decisions for reducing the number of accidents and injuries for the city."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Data\nThe data was collected by the Seattle Police Department and Accident Traffic Records Department from 2004 to present.\nThe data consists of 37 independent variables and 194,673 rows. The dependent variable, \u201cSEVERITYCODE\u201d, contains numbers that correspond to different levels of severity caused by an accident from 0 to 4.\nSeverity codes are as follows:\n0: Little to no Probability (Clear Conditions)\n1: Very Low Probability \u2014 Chance or Property Damage\n2: Low Probability \u2014 Chance of Injury\n3: Mild Probability \u2014 Chance of Serious Injury\n4: High Probability \u2014 Chance of Fatality\nFurthermore, because of the existence of null values in some records, the data needs to be preprocessed before any further processing.\n# Data Preprocessing\nThe dataset in the original form is not ready for data analysis. In order to prepare the data, first, we need to drop the non-relevant columns. In addition, most of the features are of object data types that need to be converted into numerical data types.\nAfter analyzing the data set, I have decided to focus on only four features, severity, weather conditions, road conditions, and light conditions, among others.\nTo get a good understanding of the dataset, I have checked different values in the features. The results show, the target feature is imbalance, so we use a simple statistical technique to balance it."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}